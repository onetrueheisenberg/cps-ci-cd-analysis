"""Runtime analyzer for Docker images and containers focused solely on size.

This module inspects images that are currently available on the host and
provides actionable recommendations that focus on image size. The same
size-related heuristics are applied to running containers to highlight
disk-heavy writable layers.

The script depends on the Docker CLI. When Docker is unavailable or the user
lacks sufficient permissions, a human-friendly error message is displayed
instead of raising raw subprocess exceptions.
"""

from __future__ import annotations

import argparse
import json
import shutil
import subprocess
import sys
import time
from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional


@dataclass
class Recommendation:
    """Represents a size-related optimization opportunity."""

    subject: str
    severity: str
    message: str


class DockerUnavailableError(RuntimeError):
    """Raised when Docker cannot be invoked."""


def _ensure_docker_available() -> None:
    if shutil.which("docker") is None:
        raise DockerUnavailableError(
            "Docker CLI not found in PATH. Install Docker or ensure it is accessible."
        )


def _run_docker_command(args: List[str]) -> str:
    _ensure_docker_available()
    try:
        result = subprocess.run(
            ["docker", *args],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except FileNotFoundError as exc:  # pragma: no cover - defensive guard
        raise DockerUnavailableError("Docker CLI could not be executed") from exc
    except subprocess.CalledProcessError as exc:
        raise RuntimeError(
            f"Docker command failed: docker {' '.join(args)}\n{exc.stderr.strip()}"
        ) from exc
    return result.stdout


def _parse_json_lines(output: str) -> Iterable[Dict[str, object]]:
    for line in output.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            yield json.loads(line)
        except json.JSONDecodeError:
            continue


def list_images() -> List[Dict[str, object]]:
    output = _run_docker_command([
        "images",
        "--digests",
        "--format",
        "{{json .}}",
    ])
    return list(_parse_json_lines(output))


def inspect_image(image_id: str) -> Dict[str, object]:
    output = _run_docker_command(["inspect", image_id])
    try:
        data = json.loads(output)
    except json.JSONDecodeError as exc:  # pragma: no cover - defensive guard
        raise RuntimeError(f"Failed to parse docker inspect output for {image_id}") from exc
    if not data:
        raise RuntimeError(f"docker inspect returned no data for image {image_id}")
    return data[0]


def image_history(image_id: str) -> List[Dict[str, object]]:
    output = _run_docker_command([
        "history",
        image_id,
        "--no-trunc",
        "--format",
        "{{json .}}",
    ])
    return list(_parse_json_lines(output))


def list_containers(all_containers: bool = False) -> List[Dict[str, object]]:
    args = ["ps", "--format", "{{json .}}"]
    if all_containers:
        args.insert(1, "-a")
    output = _run_docker_command(args)
    return list(_parse_json_lines(output))


def inspect_container(container_id: str) -> Dict[str, object]:
    output = _run_docker_command(["inspect", "--size", container_id])
    try:
        data = json.loads(output)
    except json.JSONDecodeError as exc:  # pragma: no cover - defensive guard
        raise RuntimeError(f"Failed to parse docker inspect output for {container_id}") from exc
    if not data:
        raise RuntimeError(f"docker inspect returned no data for container {container_id}")
    return data[0]


def _format_bytes(num_bytes: int) -> str:
    suffixes = ["B", "KB", "MB", "GB", "TB"]
    value = float(num_bytes)
    for suffix in suffixes:
        if value < 1024.0:
            return f"{value:.1f} {suffix}"
        value /= 1024.0
    return f"{value:.1f} PB"


def analyze_image(image: Dict[str, object]) -> List[Recommendation]:
    recs: List[Recommendation] = []
    image_id = str(image.get("ID"))
    repo_tags = image.get("Repository") or image.get("RepositoryName") or "<none>"
    tag = image.get("Tag") or image.get("TagName") or "<none>"
    subject = f"image {repo_tags}:{tag} ({image_id})"
    try:
        metadata = inspect_image(image_id)
    except RuntimeError as exc:
        return [Recommendation(subject=subject, severity="error", message=str(exc))]

    size_bytes = int(metadata.get("Size", 0))
    if size_bytes > 500 * 1024 * 1024:
        recs.append(
            Recommendation(
                subject,
                "info",
                (
                    "Image size exceeds 500MB ("
                    f"{_format_bytes(size_bytes)}). Consider multi-stage builds,"
                    " removing build tools, and pruning package caches."
                ),
            )
        )

    root_fs = metadata.get("RootFS", {})
    layers = root_fs.get("Layers") or []
    if isinstance(layers, list) and len(layers) > 20:
        recs.append(
            Recommendation(
                subject,
                "info",
                (
                    f"Image has {len(layers)} layers; consolidating RUN instructions or"
                    " leveraging multi-stage builds can reduce layer count and size."
                ),
            )
        )

    config = metadata.get("Config", {})
    env_vars = config.get("Env") or []
    env_dict = {env.split("=", 1)[0]: env.split("=", 1)[1] for env in env_vars if "=" in env}
    if env_dict.get("PIP_NO_CACHE_DIR") not in ("1", "true", "True"):
        recs.append(
            Recommendation(
                subject,
                "info",
                "Enable PIP_NO_CACHE_DIR=1 to avoid persisting pip caches inside the image.",
            )
        )

    history = image_history(image_id)
    large_layers = [
        layer for layer in history if layer.get("Size") and layer["Size"] not in ("0B", "0 B")
    ]
    for layer in large_layers:
        size_str = str(layer.get("Size"))
        try:
            size_value, unit = size_str.split()
            size_value = float(size_value)
        except ValueError:
            continue
        if unit.upper().startswith("GB") or (unit.upper().startswith("MB") and size_value > 200):
            created_by = str(layer.get("CreatedBy", "<unknown>"))
            recs.append(
                Recommendation(
                    subject,
                    "info",
                    (
                        f"Layer created by '{created_by}' is large ({size_str}). "
                        "Break the command into smaller steps or clean temporary artifacts to shrink the layer."
                    ),
                )
            )

    if not recs:
        recs.append(Recommendation(subject, "ok", "No issues detected for this image."))
    return recs


def analyze_container(container: Dict[str, object]) -> List[Recommendation]:
    recs: List[Recommendation] = []
    container_id = str(container.get("ID"))
    name = container.get("Names") or container.get("Name") or "<unnamed>"
    subject = f"container {name} ({container_id})"

    try:
        metadata = inspect_container(container_id)
    except RuntimeError as exc:
        return [Recommendation(subject=subject, severity="error", message=str(exc))]

    size_rw = metadata.get("SizeRw") or 0
    size_root = metadata.get("SizeRootFs") or 0

    if size_root and size_root > 500 * 1024 * 1024:
        recs.append(
            Recommendation(
                subject,
                "info",
                ("Container filesystem exceeds 500MB. Remove cached artifacts or temporary files to shrink the image footprint."),
            )
        )

    if size_rw and size_rw > 200 * 1024 * 1024:
        recs.append(
            Recommendation(
                subject,
                "suggestion",
                "Writable layer is growing (over 200MB). Rotate logs and clean transient data to keep size low.",
            )
        )

    if not recs:
        recs.append(Recommendation(subject, "ok", "No size concerns detected for this container."))
    return recs


def render_report(recommendations: Iterable[Recommendation]) -> None:
    for rec in recommendations:
        print(f"[{rec.severity.upper():9}] {rec.subject}: {rec.message}")


def analyze_once(args: argparse.Namespace) -> None:
    if args.images:
        try:
            images = list_images()
        except DockerUnavailableError as exc:
            print(str(exc), file=sys.stderr)
            return
        except RuntimeError as exc:
            print(str(exc), file=sys.stderr)
            return
        for image in images:
            render_report(analyze_image(image))

    if args.containers:
        try:
            containers = list_containers(all_containers=args.all_containers)
        except DockerUnavailableError as exc:
            print(str(exc), file=sys.stderr)
            return
        except RuntimeError as exc:
            print(str(exc), file=sys.stderr)
            return
        if not containers:
            print("No containers found.")
        for container in containers:
            render_report(analyze_container(container))


def watch_mode(args: argparse.Namespace) -> None:
    interval = args.watch
    if interval <= 0:
        print("Watch interval must be greater than zero seconds.", file=sys.stderr)
        return
    try:
        while True:
            print(time.strftime("\n=== %Y-%m-%d %H:%M:%S ==="))
            analyze_once(args)
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\nStopping watch mode.")


def parse_args(argv: Optional[List[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Analyze Docker images and containers for size optimization opportunities.",
    )
    parser.add_argument(
        "--images",
        action="store_true",
        help="Analyze local Docker images for size-related issues.",
    )
    parser.add_argument(
        "--containers",
        action="store_true",
        help="Analyze Docker containers (default: running only) for size growth.",
    )
    parser.add_argument(
        "--all-containers",
        action="store_true",
        help="Inspect stopped containers as well (implies --containers).",
    )
    parser.add_argument(
        "--watch",
        type=int,
        default=0,
        help="Continuously analyze at the provided interval in seconds.",
    )
    args = parser.parse_args(argv)

    if args.all_containers:
        args.containers = True

    if not args.images and not args.containers:
        # default to analyzing both images and running containers
        args.images = True
        args.containers = True

    return args


def main(argv: Optional[List[str]] = None) -> None:
    args = parse_args(argv)
    if args.watch:
        watch_mode(args)
    else:
        analyze_once(args)


if __name__ == "__main__":
    main()
